# AI-Driven Customer Support Agent (Voice & Chat)

## Contents
1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Project Structure](#project-structure)
4. [Tech Stack](#tech-stack)
5. [Ingesting Documents](#ingesting-documents)
6. [Features](#features)
7. [Deployment](#deployment)


## Overview

This project demonstrates a complete production-ready implementation of an AI-powered support assistant. It features multimodal interaction (voice/chat), knowledge retrieval via vector search, and integration with Vapi for real-time voice calling. The system is built with FastAPI, LangChain, Weaviate, and Streamlit, containerized with Docker, and deployable on AWS. These agents handled customer queries with human-like precision across diverse channels, reduced support ticket load, improved CSAT scores, and integrated seamlessly with CRMs and business platforms.

## Architecture

![Workflow Diagram](workflow-diagram.png)

![Block Diagram](block-diagram.png)


## ğŸ“ Project Structure

    ai-support-agent/
    â”‚
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ agents/
    â”‚   â”‚   â””â”€â”€ support_agent.py
    â”‚   â”œâ”€â”€ chains/
    â”‚   â”‚   â””â”€â”€ retrieval_chain.py
    â”‚   â”œâ”€â”€ data/
    â”‚   â”‚   â””â”€â”€ loader.py
    â”‚   â”œâ”€â”€ db/
    â”‚   â”‚   â””â”€â”€ weaviate_client.py
    â”‚   â”œâ”€â”€ endpoints/
    â”‚   â”‚   â””â”€â”€ routes.py
    â”‚   â”œâ”€â”€ services/
    â”‚   â”‚   â””â”€â”€ llm_interface.py
    â”‚   â”œâ”€â”€ vapi/
    â”‚   â”‚   â””â”€â”€ vapi_integration.py
    â”‚   â”œâ”€â”€ streamlit_app/
    â”‚   â”‚   â””â”€â”€ ui.py
    â”‚   â””â”€â”€ main.py
    â”‚
    â”œâ”€â”€ config/
    â”‚   â””â”€â”€ settings.py
    â”‚
    â”œâ”€â”€ tests/
    â”‚   â””â”€â”€ test_routes.py
    â”‚
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ .env
    â”œâ”€â”€ README.md


## ğŸ’» Tech Stack

- **Lang:** Python, TypeScript, Bash
- **Backend/API:** FastAPI
- **LLMs & Prompt Orchestration:** OpenAI (GPT-4), Claude, LangChain,
- **Knowledge Retrieval & RAG:** Weaviate (primary vector store), LlamaIndex (for document parsing and indexing)
- **Voice & Audio Interfaces:** Vapi.ai
- **Workflow Automation & Orchestration:** n8n (for business logic workflows), LangChain Agents (for tool-based tasks)
- **Observability & Tracing:** LangSmith, LLMGuard (safety filters & evaluation)
- **Frontend:** Streamlit
- **Deployment & Infrastructure:** Docker, Terraform, GitHub Actions, AWS
- **Security & Compliance:** HashiCorp Vault (secrets), OPA (policy), OAuth2, PII masking
- **3rd-Party Integrations:** SendGrid, Slack, Google Calendar (for CRM, alerts, reminders)


## ğŸš€ Quickstart

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/ai-support-agent.git
cd ai-support-agent
```

### 2. Set Environment Variables

Create `.env` file and include:

```
OPENAI_API_KEY=your-key
WEAVIATE_URL=http://localhost:8080
VAPI_API_KEY=your-vapi-key
```

### 3. Install & Run (Locally)

```bash
docker-compose up --build
```

### 4. Access the App

API: http://localhost:8000<br>
Chat UI: http://localhost:8501


## ğŸ“¥ Ingesting Documents
Drop PDFs or .txt files into a folder and run:

```bash
python app/ingestion/document_ingestor.py
```

## ğŸ“ Voice Call Setup
Make sure your Vapi account is configured correctly. Voice calls can be handled in:

```bash
app/vapi/voice_router.py
```

## ğŸ§  Features
- Context-aware, memory-capable chat
- RAG (Retrieval-Augmented Generation) for domain-specific queries
- Voice interaction using Vapi
- Deployable locally or to the cloud
- Easily extendable with more agents, tools, or endpoints

## ğŸ“¦ Deployment
- Use the included Docker setup to deploy the API, Weaviate, and Streamlit UI.
- For AWS: Containerize with ECR or ECS
- Attach persistent volume to Weaviate if needed
- Secure API with IAM/SSL/Gateway
